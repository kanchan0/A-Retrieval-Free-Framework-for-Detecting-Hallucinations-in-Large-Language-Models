{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5uGPfDElJuq6"
   },
   "outputs": [],
   "source": [
    "#!pip install -q transformers accelerate sentencepiece --upgrade\n",
    "\n",
    "import re\n",
    "import math\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "4645beb3e4db4bbab6e40d28d236449c",
      "4ad8e693df254179b5769280936cc191",
      "3de928456220464393dd5d92562ca13e",
      "bffb14b9937f4b298a56e0669c52ea95",
      "6a60e68205274cc8bd382a23c9026570",
      "6e14f889912d4dbb8c14e7d590528226",
      "f813bd41cd14401188c5bc6aa6fe67fc",
      "4e54df4969e14a4b863fddbebc8dc273",
      "a6e4e77972f243c2b3abafdabd234873",
      "d138f1d5b07e495c908dcfc5064bd429",
      "bdd226dddff84012bd6cd2291064e830",
      "e90d3bc64f6d4e389c86672b5ae86de4",
      "feccf276457a4dc9ac0014bd93f92c97",
      "b3aba8b5a45648258d522e02312efff8",
      "27887fb3ab8840bc8b16b0d09153119e",
      "1e8941a94911491896cb8ad253f6532d",
      "cb95ad46b9774d40a0510193e5b770a1",
      "5295b4f66fa6416bb27d49f003143c40",
      "696bdac7b8d1460f9e443906a958810e",
      "f04048ec4e544c269767382aec4df5f2"
     ]
    },
    "id": "2mdH24KDKAYr",
    "outputId": "52bc9af2-aa3c-4dd9-a5cd-f9b88df7d58a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4645beb3e4db4bbab6e40d28d236449c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 1b: HuggingFace token (REQUIRED for LLaMA 3)\n",
    "from huggingface_hub import login\n",
    "login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585,
     "referenced_widgets": [
      "bd65f8b60d4d43618647a5ceda1ac108",
      "37d6e7452a49466798429dc07a0beb99",
      "95a090b51fb54a6fa9a9de63cb70f27b",
      "1a85e3a635b64da7b2234a5f86e9a9e0",
      "2444deba0ff1455ab996e20dca695b35",
      "906e6e0c296b4d12944a0c9a165c66c7",
      "d7d22685e248441a870ec88325eb9c4b",
      "e7948302775440d6b0ba7aa7f6b7ba22",
      "70f3ac4c65b645bca1330a9049c2587b",
      "1616867b6c5c40e1a3ec8a88c182f210",
      "5b8b0c808a3e4e788449724cd34e11ae",
      "8d61c3bab040409396dc23811f4a037b",
      "c03a9c7313fb4a99a47161ec47e807f2",
      "4846ad4fcce54558a595eb41aa293aed",
      "a30c259e5e704d65ab52aac170e1ccaf",
      "0114cc1acc834daf9bb8434e9c9bf5c1",
      "dad03af945b74071ad433e24768f50ef",
      "3a215472eb6143b9ac92a87263a40f5d",
      "298b7198e40b4696802f93a9ee139185",
      "a521728b3fd040d48541464462fde744",
      "5cb73ccdf6314f30b8c8ce8b8a5509e6",
      "447b37bcc943421d861ca58132c026c4",
      "116c423e5e7d417a800829e2b31bd452",
      "e5cca23a0cf5458bb9b09b3b450df143",
      "98f1cc2f34934a118edbfbf639443d87",
      "3380ce827bcb4a1f88ce5152a6004db0",
      "464d6e186b0b4a498719eb976aec9863",
      "5c0c466b22034749ac3b7d96391e658b",
      "b89a63cafda441e99bf3b71a6c73e86b",
      "fdfd1837655e4b7d8d0993adbc959f68",
      "27a191b7842a417d8155ce6ac5cab985",
      "03640108832045c3954a911c67a39da0",
      "9aa1518f526546b0aeca9d2888fc3161",
      "e04e6dcbfa26449f8a43947978fc2143",
      "2e92eebc1339452c86439e25c5885025",
      "40795e7211cd48deacb5a2d230a7316e",
      "46de0f4a731f42d98e9968905c944190",
      "cbcac6d51b494838958e69c28ea016e0",
      "f3860f6624bd4b3abd2413292e6e4011",
      "2123c26cbe044af58c88c6ddebde2a51",
      "02b6b8826e5842338cec21a9bfad1931",
      "d3b0c248863d40918955a01f33970782",
      "a125d2eb05ab40e29da8174d4789bde7",
      "ad65485acada477386dc1cb04670c874",
      "e2dd0488dd15499187c720ca49716e90",
      "f306c6b4dab640bc870ad4340f789d64",
      "92ed611af0e74f46bc8b3f3adbd86d76",
      "7dd7573c13024a6b87012ad4291d4e0f",
      "5a100eae283d4d7e8082b82687b14122",
      "b7679fef8cca49a7b8520381dbfa7db7",
      "dc61823018e5423c92c9183b014b4c8f",
      "78335de2b4924248ba23b542c086f233",
      "6f34a8dfb6124617ba8cb28a20f32467",
      "4400a111d0b147a58ba2c7284c33a32b",
      "c5645bd47dd048a0a45e20f90b8c3370",
      "09a8868bdeca44548c650dd7821bf758",
      "5ab5ab73a2ca47268161cfed1af42976",
      "d026dac0da3840098fd416f8ae0b6c3b",
      "a7091536a45c49369baf7064d1496e2a",
      "bb2adb93724f4effa76e0f264f5fa68f",
      "985bdeeac95d4d5ca6ab7fc17bb319ed",
      "7169863783e549aa9910a84ab6c4cc9b",
      "71d108448fe74de99266ccb39bb389b5",
      "851415e6d8a043d783c3a19f7e440107",
      "61f06db5a4404c179aaf00105921f5b9",
      "517febd17b914a5992468801540e3e7c",
      "bcb73b6684244287aba5a317701f9ad4",
      "3453cbc1d2d043c39d7359d5053a06a7",
      "b59824bbab5747848bc2ed35e24ed1c8",
      "0bcb6dcfbaa44fd9a0a77e388c09cf59",
      "da16825accec4d16b86adbefc846a8cb",
      "e1406e9af3fc44d38dddac85e09bbdac",
      "51c56ee0683841fba6107a4d85bdd09a",
      "d2c34ad00d9842eab33c934402cbb467",
      "0c85f74e0d424fb1a3959a41edab5c9c",
      "6e972f8503c04c34aef7e123d2a8f02e",
      "e75bf88ed3364ddab8f195c8e06d2e89",
      "0543b2a44cf24ea2b32d0490b1c4914d",
      "df7c8daef74b4073b287815ce52cd6bf",
      "d421a7bc1e3147c8bda755da7c7a2c69",
      "14f2b18936e94162b02b27b33612ac30",
      "50940fa3ef5a4fa697ac831d1a0a7a8d",
      "58f5fb0fd0104c3ea98dc6991fb6c064",
      "ee45bcae569e4d9bb5d3eaabbb3ccf3d",
      "4ffd5cd40cea4df088fc4db4f7ae5d96",
      "45960814fe90436f9be1d440b24efa8a",
      "c1339265c61e4cbbb5edb6fce4df9561",
      "08778d9a5a1b46a19eeaf0306666c52e",
      "aab3c6db86264e59a69556b167c4548b",
      "5e59d2d9fc5b4255b31b2a5c36c5e679",
      "7ee767bac9a64a3ab0cb7a32038de31a",
      "03740aec2fbf4a3cbcf1d3d1845d8336",
      "c0b513e327e34ee3a8a278ea626b5bec",
      "c3ca36212dde4f2b85cd973e310c1eca",
      "559d63d9972b44eeba84f23130936175",
      "d863027a73a14096830ff6ca0aa24076",
      "808403b7d17144aba9290a1e050115f9",
      "8bebed29122940ea9e2475acb8a1ec5a",
      "2a0c255a6ff14a0994fec1dc8f57f627",
      "6c5f3d0a4e8449e0bc09c2101d9da719",
      "53f52e2612fb41e8923796b77e4a5701",
      "601dd48ae3d04220b7b2b27df182f2c9",
      "1e1dd844443146f0958350d806a27668",
      "b3ae49b8ba4240f8beb998b9078e31ab",
      "5548c7566af141198d5360b03735788a",
      "c8d716f349774a999fb1e4fb0d8846fb",
      "2c79c7a42f824b75b1cc6670db099762",
      "42d76caa14204dc69b09a02e33706a3e",
      "91d35d46c07d481c83a459f165e1d63a",
      "ec9346c53e474d4e9271b13001465a99",
      "b5d9c456cae545b5b27bccbd8fea2c73",
      "2e69fa051cfd4cd0999ba0abdc140b13",
      "a7fd03010f7d4ef88ca7a6632a9db8f8",
      "94a6e7e44ccd4206bb1cb4c8bc82320d",
      "c3f14367a8af4eec9e8047b20aab638a",
      "2d25d8ddd56a4bde8174f042de36fc77",
      "9cf43c13756a4c3680600f75c7b69a1c",
      "00af01f25e0d488fbd3df4b41190d3c8",
      "822b4ca3b5c74ca2a83ded254396d98b",
      "9a6689087b0d4b728df7116c3c83619f",
      "c0f3c5850a114caeb2f265b8c784b56b",
      "e67f91d84da04570b966a6e2cf2c8506",
      "e8ebaf8d981341c099b29606f1fb1be1",
      "b4bbcf1d57b14e7899cf40689d668d7c",
      "cb488b2330e5488a97d99dfb98004980",
      "37dfa86c5e594b5e9270988560df6273",
      "23a91de29b5c4694bc27fd9c5db25f4a",
      "e8f169a2a4ff4696ab7a437b18eaa393",
      "141d03f8607a4660bbf058cdae283a28",
      "70d5faf180804a3a9f0e0a8c3c642f85",
      "b2e260b1a49147ea9d08d2a1e90fd828",
      "a66ee383c7114de59fca8a98ca28f209"
     ]
    },
    "id": "2vzXHcKbKHXo",
    "outputId": "1afeeeb5-774a-4710-d4ce-17b33806f98c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd65f8b60d4d43618647a5ceda1ac108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d61c3bab040409396dc23811f4a037b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116c423e5e7d417a800829e2b31bd452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04e6dcbfa26449f8a43947978fc2143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2dd0488dd15499187c720ca49716e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a8868bdeca44548c650dd7821bf758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb73b6684244287aba5a317701f9ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0543b2a44cf24ea2b32d0490b1c4914d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab3c6db86264e59a69556b167c4548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5f3d0a4e8449e0bc09c2101d9da719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d9c456cae545b5b27bccbd8fea2c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67f91d84da04570b966a6e2cf2c8506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_mistral_7b_instruct():\n",
    "    model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    )\n",
    "    model.eval()\n",
    "    return model, tokenizer\n",
    "\n",
    "model, tokenizer = load_mistral_7b_instruct()\n",
    "device = next(model.parameters()).device\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vG4w26A_KtHK"
   },
   "outputs": [],
   "source": [
    "# Cell 3: Claim extraction\n",
    "\n",
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "\n",
    "def is_factual_sentence(sentence: str) -> bool:\n",
    "    has_digit = bool(re.search(r'\\d', sentence))\n",
    "    has_capital = bool(re.search(r'\\b[A-Z][a-zA-Z]+\\b', sentence))\n",
    "    factual_verbs = [\"is\", \"was\", \"were\", \"are\",\n",
    "                     \"founded\", \"discovered\", \"invented\",\n",
    "                     \"located\", \"born\"]\n",
    "    has_verb = any(v in sentence.lower() for v in factual_verbs)\n",
    "    return has_digit or has_capital or has_verb\n",
    "\n",
    "\n",
    "def extract_claims(response: str) -> List[str]:\n",
    "    sentences = split_into_sentences(response)\n",
    "    return [s for s in sentences if is_factual_sentence(s)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pc9AyEsnKwHH"
   },
   "outputs": [],
   "source": [
    "# Cell 4: Token-level uncertainty\n",
    "\n",
    "import math\n",
    "\n",
    "def compute_token_stats(model, tokenizer, prompt: str, claim: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute mean log-probability, entropy and logit gap for tokens\n",
    "    in the claim, conditioned on the prompt. Robust to edge cases\n",
    "    where the claim slice is empty.\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    full_text = prompt + \"\\n\" + claim\n",
    "\n",
    "    enc = tokenizer(full_text, return_tensors=\"pt\")\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attn = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attn)\n",
    "        logits = outputs.logits  # (1, seq_len, vocab)\n",
    "\n",
    "    # Prompt length (separate encoding)\n",
    "    enc_prompt = tokenizer(prompt + \"\\n\", return_tensors=\"pt\")\n",
    "    prompt_len = enc_prompt[\"input_ids\"].shape[1]\n",
    "\n",
    "    # Shift for LM\n",
    "    logits = logits[:, :-1, :]\n",
    "    targets = input_ids[:, 1:]\n",
    "\n",
    "    # Claim region\n",
    "    claim_start = max(prompt_len - 1, 0)\n",
    "    if claim_start >= logits.shape[1]:\n",
    "        # No claim tokens found – return neutral defaults\n",
    "        return {\n",
    "            \"mean_logp\": 0.0,\n",
    "            \"entropy\": 0.0,\n",
    "            \"logit_gap\": 0.0,\n",
    "        }\n",
    "\n",
    "    claim_logits = logits[:, claim_start:, :]\n",
    "    claim_targets = targets[:, claim_start:]\n",
    "\n",
    "    if claim_logits.shape[1] == 0:\n",
    "        # Again, empty – avoid NaN\n",
    "        return {\n",
    "            \"mean_logp\": 0.0,\n",
    "            \"entropy\": 0.0,\n",
    "            \"logit_gap\": 0.0,\n",
    "        }\n",
    "\n",
    "    # Log-probs of actual tokens\n",
    "    log_probs = torch.log_softmax(claim_logits, dim=-1)\n",
    "    tgt_log_probs = log_probs.gather(-1, claim_targets.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    # Entropy per position\n",
    "    probs = torch.softmax(claim_logits, dim=-1)\n",
    "    entropy = -(probs * torch.log(probs + 1e-12)).sum(dim=-1)\n",
    "\n",
    "    # Logit gap\n",
    "    top2 = torch.topk(claim_logits, k=2, dim=-1).values\n",
    "    logit_gap = (top2[..., 0] - top2[..., 1]).mean().item()\n",
    "\n",
    "    mean_logp = tgt_log_probs.mean().item()\n",
    "    mean_entropy = entropy.mean().item()\n",
    "\n",
    "    # Extra safety: strip NaNs if any\n",
    "    if math.isnan(mean_logp):\n",
    "        mean_logp = 0.0\n",
    "    if math.isnan(mean_entropy):\n",
    "        mean_entropy = 0.0\n",
    "    if math.isnan(logit_gap):\n",
    "        logit_gap = 0.0\n",
    "\n",
    "    return {\n",
    "        \"mean_logp\": float(mean_logp),\n",
    "        \"entropy\": float(mean_entropy),\n",
    "        \"logit_gap\": float(logit_gap),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kwKQqjksKzrG"
   },
   "outputs": [],
   "source": [
    "# Cell 5: Sampling-based self-consistency\n",
    "\n",
    "def generate_response(model, tokenizer, prompt: str,\n",
    "                      max_new_tokens: int = 128,\n",
    "                      temperature: float = 0.7,\n",
    "                      top_p: float = 0.9) -> str:\n",
    "    \"\"\"\n",
    "    Simple generation for LLaMA 3 Instruct.\n",
    "    Using plain text prompt is fine for our use-case.\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    enc = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    generated = tokenizer.decode(\n",
    "        out_ids[0][enc[\"input_ids\"].shape[1]:],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return generated.strip()\n",
    "\n",
    "\n",
    "def generate_samples(model, tokenizer, prompt: str,\n",
    "                     k: int = 4, max_new_tokens: int = 128) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate k alternative responses (lower k for LLaMA to save time).\n",
    "    \"\"\"\n",
    "    return [\n",
    "        generate_response(model, tokenizer, prompt, max_new_tokens=max_new_tokens)\n",
    "        for _ in range(k)\n",
    "    ]\n",
    "\n",
    "\n",
    "def simple_normalize(text: str) -> str:\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def compute_agreement_for_claim(claim: str,\n",
    "                                prompt: str,\n",
    "                                samples: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Lightweight Jaccard-based similarity between the claim\n",
    "    and sentences from sampled responses.\n",
    "    \"\"\"\n",
    "    target_norm = simple_normalize(claim)\n",
    "    matches = 0\n",
    "\n",
    "    for sample in samples:\n",
    "        sample_sents = split_into_sentences(sample)\n",
    "        best_sim = 0.0\n",
    "        for s in sample_sents:\n",
    "            s_norm = simple_normalize(s)\n",
    "            set_a = set(target_norm.split())\n",
    "            set_b = set(s_norm.split())\n",
    "            if not set_a or not set_b:\n",
    "                continue\n",
    "            sim = len(set_a & set_b) / len(set_a | set_b)\n",
    "            best_sim = max(best_sim, sim)\n",
    "        if best_sim > 0.6:\n",
    "            matches += 1\n",
    "\n",
    "    if not samples:\n",
    "        return 0.0\n",
    "    return matches / len(samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fCYDN6H-K2lj"
   },
   "outputs": [],
   "source": [
    "# Cell 6: Self-verification\n",
    "\n",
    "def ask_self_verification(model, tokenizer, claim: str,\n",
    "                          max_new_tokens: int = 64) -> float:\n",
    "    \"\"\"\n",
    "    Ask llm to rate its confidence in a claim on [0,1].\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    prompt = (\n",
    "        f\"Claim: {claim}\\n\"\n",
    "        \"On a scale from 0 to 1, how confident are you that this claim is correct?\\n\"\n",
    "        \"First output only the number on the first line, then write 1-2 sentences explaining your reasoning.\"\n",
    "    )\n",
    "\n",
    "    enc = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out_ids = model.generate(\n",
    "            **enc,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    generated = tokenizer.decode(\n",
    "        out_ids[0][enc[\"input_ids\"].shape[1]:],\n",
    "        skip_special_tokens=True\n",
    "    ).strip()\n",
    "\n",
    "    first_line = generated.splitlines()[0].strip()\n",
    "    try:\n",
    "        val = float(first_line)\n",
    "        return max(0.0, min(1.0, val))\n",
    "    except ValueError:\n",
    "        return 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xVb6RYIGK5d4"
   },
   "outputs": [],
   "source": [
    "# Cell 7: Feature normalization and aggregation\n",
    "\n",
    "def normalize_feature(values: List[float]) -> List[float]:\n",
    "    \"\"\"\n",
    "    Min-max normalize to [0,1], with NaN-safe handling.\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return values\n",
    "\n",
    "    # Replace NaN or inf with 0.0 first\n",
    "    clean = []\n",
    "    for v in values:\n",
    "        if v is None or math.isnan(v) or math.isinf(v):\n",
    "            clean.append(0.0)\n",
    "        else:\n",
    "            clean.append(v)\n",
    "\n",
    "    vmin, vmax = min(clean), max(clean)\n",
    "    if math.isclose(vmin, vmax):\n",
    "        return [0.5] * len(values)\n",
    "\n",
    "    normed = []\n",
    "    for v in clean:\n",
    "        normed.append((v - vmin) / (vmax - vmin))\n",
    "    return normed\n",
    "\n",
    "\n",
    "def compute_hallucination_scores(\n",
    "    claims: List[str],\n",
    "    stats_list: List[Dict[str, float]],\n",
    "    agreements: List[float],\n",
    "    self_confs: List[float]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Aggregate features into a hallucination score in [0,1] for each claim.\n",
    "    NaN-safe and uses conservative weights.\n",
    "    \"\"\"\n",
    "    def safe(x: float) -> float:\n",
    "        if x is None or math.isnan(x) or math.isinf(x):\n",
    "            return 0.0\n",
    "        return x\n",
    "\n",
    "    mean_logps = [safe(s[\"mean_logp\"]) for s in stats_list]\n",
    "    entropies  = [safe(s[\"entropy\"]) for s in stats_list]\n",
    "    gaps       = [safe(s[\"logit_gap\"]) for s in stats_list]\n",
    "    agreements = [safe(a) for a in agreements]\n",
    "    self_confs = [safe(c) for c in self_confs]\n",
    "\n",
    "    mean_logps_norm = normalize_feature(mean_logps)\n",
    "    entropies_norm  = normalize_feature(entropies)\n",
    "    gaps_norm       = normalize_feature(gaps)\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    # More conservative weights + negative bias\n",
    "    w1, w2, w3, w4, w5 = 0.5, 0.5, 0.5, 0.8, 0.5\n",
    "    b = -1.0\n",
    "\n",
    "    for i, c in enumerate(claims):\n",
    "        f1 = 1 - mean_logps_norm[i]\n",
    "        f2 = entropies_norm[i]\n",
    "        f3 = 1 - gaps_norm[i]\n",
    "        f4 = 1 - agreements[i]\n",
    "        f5 = 1 - self_confs[i]\n",
    "\n",
    "        z = w1*f1 + w2*f2 + w3*f3 + w4*f4 + w5*f5 + b\n",
    "        score = 1 / (1 + math.exp(-z))\n",
    "\n",
    "        if math.isnan(score) or math.isinf(score):\n",
    "            score = 0.5\n",
    "\n",
    "        scores[c] = score\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "eWbNfM5XK_nv",
    "outputId": "a29637cd-9386-4cfa-b99c-674babc8bed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      " Who discovered penicillin and in which year? Explain briefly.\n",
      "\n",
      "RESPONSE:\n",
      " Penicillin, the world's first antibiotic, was discovered accidentally by Alexander Fleming in 1928. Fleming was a Scottish bacteriologist and physician, working at St. Mary's Hospital in London. He returned from his annual summer holiday to find his laboratory in disarray. Among the mess, he noticed a petri dish that\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"claim\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"He returned from his annual summer holiday to find his laboratory in disarray.\",\n          \"Penicillin, the world's first antibiotic, was discovered accidentally by Alexander Fleming in 1928.\",\n          \"Mary's Hospital in London.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hallucination_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17629134034245017,\n        \"min\": 0.3262929005454786,\n        \"max\": 0.7810997693287104,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7059657286029861,\n          0.3262929005454786,\n          0.6513268159073397\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-bbfbac44-b97c-4ad9-85c2-02c69277f5a9\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>hallucination_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Among the mess, he noticed a petri dish that</td>\n",
       "      <td>0.781100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He returned from his annual summer holiday to ...</td>\n",
       "      <td>0.705966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary's Hospital in London.</td>\n",
       "      <td>0.651327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fleming was a Scottish bacteriologist and phys...</td>\n",
       "      <td>0.547390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Penicillin, the world's first antibiotic, was ...</td>\n",
       "      <td>0.326293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbfbac44-b97c-4ad9-85c2-02c69277f5a9')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-bbfbac44-b97c-4ad9-85c2-02c69277f5a9 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-bbfbac44-b97c-4ad9-85c2-02c69277f5a9');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-5446d879-e04c-4cca-85b3-77c7897273cd\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5446d879-e04c-4cca-85b3-77c7897273cd')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-5446d879-e04c-4cca-85b3-77c7897273cd button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_93510dc7-a782-436a-bcdf-d0e7003e0ce3\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_93510dc7-a782-436a-bcdf-d0e7003e0ce3 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                               claim  hallucination_score\n",
       "0       Among the mess, he noticed a petri dish that             0.781100\n",
       "1  He returned from his annual summer holiday to ...             0.705966\n",
       "2                         Mary's Hospital in London.             0.651327\n",
       "3  Fleming was a Scottish bacteriologist and phys...             0.547390\n",
       "4  Penicillin, the world's first antibiotic, was ...             0.326293"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8: Pretty display of hallucination scores using pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def scores_to_dataframe(scores: Dict[str, float]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a {claim: score} dict into a sorted pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if not scores:\n",
    "        return pd.DataFrame(columns=[\"claim\", \"hallucination_score\"])\n",
    "    data = [{\"claim\": c, \"hallucination_score\": s} for c, s in scores.items()]\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values(by=\"hallucination_score\", ascending=False).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example: rerun previous detection and show as table\n",
    "\n",
    "prompt = \"Who discovered penicillin and in which year? Explain briefly.\"\n",
    "response = generate_response(model, tokenizer, prompt, max_new_tokens=80)\n",
    "\n",
    "print(\"PROMPT:\\n\", prompt)\n",
    "print(\"\\nRESPONSE:\\n\", response)\n",
    "\n",
    "scores = hall_detect(\n",
    "    model, tokenizer,\n",
    "    prompt, response,\n",
    "    k_samples=3,\n",
    "    max_new_tokens=80\n",
    ")\n",
    "\n",
    "df = scores_to_dataframe(scores)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSlE1cpkmEVr"
   },
   "source": [
    "For this example, the core factual statement regarding the discovery of penicillin obtains a hallucination score of approximately **0.49**, placing it in the **low-risk band** of the detector. This aligns with expectations, since this claim is well-established, unambiguous, and internally stable across sampling. In contrast, the incomplete or fragmented sentences that describe the broader narrative of Fleming’s work register substantially higher scores (ranging from **0.70 to 0.77**). These values arise not because the content is necessarily incorrect, but because such fragments exhibit **higher generative entropy**, **lower sampling consistency**, and **less stable token-level probabilities**.\n",
    "\n",
    "This behaviour highlights an important characteristic of **Kanchan’s-HALL-Detect**: it does not simply flag factual errors, but more broadly captures **structural instability**, **uncertainty**, and **inconsistency** within the model’s own generative process. As a result, even factually accurate statements may be marked as higher-risk if they are poorly structured or only partially generated, which is a desirable property for a retrieval-free hallucination detection method.\n",
    "\n",
    "It is also important to acknowledge that, in the current implementation, all feature weights in the aggregation step are **fixed and hand-tuned**. With proper calibration or fine-tuning on a labelled hallucination dataset, the model’s discrimination ability would almost certainly improve. Nonetheless, this initial experiment demonstrates that the proposed approach is **functionally sound and directionally correct**, successfully separating stable factual claims from unstable or behaviourally suspicious ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "97uw0PrRLD_X",
    "outputId": "43cdcd1d-06b2-40dc-ce81-f5f142581af2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"batch_df\",\n  \"rows\": 11,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Who won the FIFA World Cup in 2010?\",\n          \"Who discovered penicillin and in which year?\",\n          \"Tell me about the capital city of Australia.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"The 2010 FIFA World Cup was won by Spain. Spain defeated the Netherlands 1-0 in the final, held on July 11, 2010 at Soccer City in Johannesburg, South Africa. Andres Iniesta scored the winning goal in extra time, in a match that is widely regarded as one of the best in World Cup history\",\n          \"Alexander Fleming is credited with the discovery of penicillin, an antibiotic that revolutionized medicine, in 1928. He noticed that a mold growing in a Petri dish near one of his Staphylococcus cultures had produced a substance that killed the bacteria surrounding it. Fleming named the mold Penicillium chrys\",\n          \"What is it famous for?\\n\\nThe capital city of Australia is Canberra. It is located in the Australian Capital Territory (ACT), which is not a part of any Australian state. Canberra was purpose-built as the capital city and was designed to be a combination of a bush capital and an international city.\\n\\nCanberra is famous for its beautiful gardens, museum\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"claim\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"He noticed that a mold growing in a Petri dish near one of his Staphylococcus cultures had produced a substance that killed the bacteria surrounding it.\",\n          \"Andres Iniesta scored the winning goal in extra time, in a match that is widely regarded as one of the best in World Cup history\",\n          \"The capital city of Australia is Canberra.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hallucination_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16205133900053464,\n        \"min\": 0.3219117504483725,\n        \"max\": 0.8175744761936437,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.7284310992744428,\n          0.8175744761936437,\n          0.49166743818588077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "batch_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-f5c75cd3-d6e4-48ec-a706-8ecada95e1b6\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>claim</th>\n",
       "      <th>hallucination_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who won the FIFA World Cup in 2010?</td>\n",
       "      <td>The 2010 FIFA World Cup was won by Spain. Spai...</td>\n",
       "      <td>Andres Iniesta scored the winning goal in extr...</td>\n",
       "      <td>0.817574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who discovered penicillin and in which year?</td>\n",
       "      <td>Alexander Fleming is credited with the discove...</td>\n",
       "      <td>Fleming named the mold Penicillium chrys</td>\n",
       "      <td>0.802259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tell me about the capital city of Australia.</td>\n",
       "      <td>What is it famous for?\\n\\nThe capital city of ...</td>\n",
       "      <td>What is it famous for?</td>\n",
       "      <td>0.791012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tell me about the capital city of Australia.</td>\n",
       "      <td>What is it famous for?\\n\\nThe capital city of ...</td>\n",
       "      <td>Canberra was purpose-built as the capital city...</td>\n",
       "      <td>0.780356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tell me about the capital city of Australia.</td>\n",
       "      <td>What is it famous for?\\n\\nThe capital city of ...</td>\n",
       "      <td>Canberra is famous for its beautiful gardens, ...</td>\n",
       "      <td>0.771157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who discovered penicillin and in which year?</td>\n",
       "      <td>Alexander Fleming is credited with the discove...</td>\n",
       "      <td>He noticed that a mold growing in a Petri dish...</td>\n",
       "      <td>0.728431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tell me about the capital city of Australia.</td>\n",
       "      <td>What is it famous for?\\n\\nThe capital city of ...</td>\n",
       "      <td>It is located in the Australian Capital Territ...</td>\n",
       "      <td>0.609333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who discovered penicillin and in which year?</td>\n",
       "      <td>Alexander Fleming is credited with the discove...</td>\n",
       "      <td>Alexander Fleming is credited with the discove...</td>\n",
       "      <td>0.558070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Who won the FIFA World Cup in 2010?</td>\n",
       "      <td>The 2010 FIFA World Cup was won by Spain. Spai...</td>\n",
       "      <td>Spain defeated the Netherlands 1-0 in the fina...</td>\n",
       "      <td>0.544106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tell me about the capital city of Australia.</td>\n",
       "      <td>What is it famous for?\\n\\nThe capital city of ...</td>\n",
       "      <td>The capital city of Australia is Canberra.</td>\n",
       "      <td>0.491667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Who won the FIFA World Cup in 2010?</td>\n",
       "      <td>The 2010 FIFA World Cup was won by Spain. Spai...</td>\n",
       "      <td>The 2010 FIFA World Cup was won by Spain.</td>\n",
       "      <td>0.321912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5c75cd3-d6e4-48ec-a706-8ecada95e1b6')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-f5c75cd3-d6e4-48ec-a706-8ecada95e1b6 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-f5c75cd3-d6e4-48ec-a706-8ecada95e1b6');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-b3260c82-a4ef-429f-a269-226f9608add2\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3260c82-a4ef-429f-a269-226f9608add2')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-b3260c82-a4ef-429f-a269-226f9608add2 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_9ce8d320-7783-48df-9dcb-2505d9a00419\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('batch_df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_9ce8d320-7783-48df-9dcb-2505d9a00419 button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('batch_df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                          prompt  \\\n",
       "0            Who won the FIFA World Cup in 2010?   \n",
       "1   Who discovered penicillin and in which year?   \n",
       "2   Tell me about the capital city of Australia.   \n",
       "3   Tell me about the capital city of Australia.   \n",
       "4   Tell me about the capital city of Australia.   \n",
       "5   Who discovered penicillin and in which year?   \n",
       "6   Tell me about the capital city of Australia.   \n",
       "7   Who discovered penicillin and in which year?   \n",
       "8            Who won the FIFA World Cup in 2010?   \n",
       "9   Tell me about the capital city of Australia.   \n",
       "10           Who won the FIFA World Cup in 2010?   \n",
       "\n",
       "                                             response  \\\n",
       "0   The 2010 FIFA World Cup was won by Spain. Spai...   \n",
       "1   Alexander Fleming is credited with the discove...   \n",
       "2   What is it famous for?\\n\\nThe capital city of ...   \n",
       "3   What is it famous for?\\n\\nThe capital city of ...   \n",
       "4   What is it famous for?\\n\\nThe capital city of ...   \n",
       "5   Alexander Fleming is credited with the discove...   \n",
       "6   What is it famous for?\\n\\nThe capital city of ...   \n",
       "7   Alexander Fleming is credited with the discove...   \n",
       "8   The 2010 FIFA World Cup was won by Spain. Spai...   \n",
       "9   What is it famous for?\\n\\nThe capital city of ...   \n",
       "10  The 2010 FIFA World Cup was won by Spain. Spai...   \n",
       "\n",
       "                                                claim  hallucination_score  \n",
       "0   Andres Iniesta scored the winning goal in extr...             0.817574  \n",
       "1            Fleming named the mold Penicillium chrys             0.802259  \n",
       "2                              What is it famous for?             0.791012  \n",
       "3   Canberra was purpose-built as the capital city...             0.780356  \n",
       "4   Canberra is famous for its beautiful gardens, ...             0.771157  \n",
       "5   He noticed that a mold growing in a Petri dish...             0.728431  \n",
       "6   It is located in the Australian Capital Territ...             0.609333  \n",
       "7   Alexander Fleming is credited with the discove...             0.558070  \n",
       "8   Spain defeated the Netherlands 1-0 in the fina...             0.544106  \n",
       "9          The capital city of Australia is Canberra.             0.491667  \n",
       "10          The 2010 FIFA World Cup was won by Spain.             0.321912  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 10: Batch evaluation on multiple prompts\n",
    "\n",
    "def run_batch_hallucination_detection(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompts: List[str],\n",
    "    k_samples: int = 3,\n",
    "    max_new_tokens: int = 80\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run Kanchan's-HALL-Detect on a list of prompts.\n",
    "    Returns a single DataFrame with columns:\n",
    "    [prompt, response, claim, hallucination_score].\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        # Generate one response\n",
    "        response = generate_response(model, tokenizer, prompt, max_new_tokens=max_new_tokens)\n",
    "        scores = hall_detect(\n",
    "            model, tokenizer,\n",
    "            prompt, response,\n",
    "            k_samples=k_samples,\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )\n",
    "\n",
    "        if not scores:\n",
    "            all_rows.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": response,\n",
    "                \"claim\": None,\n",
    "                \"hallucination_score\": None\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        for claim, score in scores.items():\n",
    "            all_rows.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": response,\n",
    "                \"claim\": claim,\n",
    "                \"hallucination_score\": score\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    if not df.empty:\n",
    "        df = df.sort_values(\n",
    "            by=[\"hallucination_score\"],\n",
    "            ascending=False\n",
    "        ).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example batch\n",
    "prompts = [\n",
    "    \"Who discovered penicillin and in which year?\",\n",
    "    \"Tell me about the capital city of Australia.\",\n",
    "    \"Who won the FIFA World Cup in 2010?\",\n",
    "]\n",
    "\n",
    "batch_df = run_batch_hallucination_detection(\n",
    "    model, tokenizer,\n",
    "    prompts,\n",
    "    k_samples=3,\n",
    "    max_new_tokens=80\n",
    ")\n",
    "\n",
    "batch_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JiJhzGOoQfa"
   },
   "source": [
    "**1. Penicillin Discovery Prompt**\n",
    "The core fact “Penicillin was discovered by Alexander Fleming in 1928” receives a low-to-moderate score (~0.49–0.56).\n",
    "\n",
    "This aligns with expectations because this claim is well-established and appears consistently across sampled generations.More detailed or narrative statements (e.g., Fleming’s activities, lab conditions, or specific dates) receive higher scores (~0.70–0.80).\n",
    "\n",
    "Reason:\n",
    "These extended claims exhibit higher generative entropy and lower sampling agreement. Even when factual, they are behaviorally less stable than the core fact.\n",
    "\n",
    "**2. Capital of Australia Prompt**\n",
    "\n",
    "The main fact “Canberra is the capital city of Australia” receives low scores (~0.49–0.60).Claims describing features of Canberra (e.g., gardens, museums, city design) or incomplete fragments (e.g., “What is it famous for?”) receive higher scores (~0.75–0.79).\n",
    "\n",
    "Reason:\n",
    "Descriptive or open-ended content varies across samples and contains higher uncertainty. Sentence fragments also inflate risk due to incomplete structure.\n",
    "\n",
    "**3. FIFA World Cup 2010 Prompt**\n",
    "\n",
    "The primary fact “Spain won the 2010 FIFA World Cup” receives the lowest score (~0.32), indicating very low hallucination risk.Extended match details (e.g., goal scorer, match dynamics, extra time) receive higher scores (~0.54–0.82).\n",
    "\n",
    "Reason:\n",
    "These details vary more across generations. Although correct, they exhibit less stability, higher entropy, and inconsistent phrasing, which the detector flags as higher risk.\n",
    "\n",
    "--------------------------------------------------------------------These results demonstrate that Kanchan’s-HALL-Detect does not only measure factual correctness but also detects structural instability and probabilistic uncertainty within the model’s outputs. Even accurate statements can receive higher scores if they are incomplete, descriptive, or expressed inconsistently.\n",
    "\n",
    "Furthermore, since the aggregation weights in this prototype are fixed and not fine-tuned, the current results should be seen as directionally correct but improvable. With proper calibration on labeled data, the precision of these scores would naturally increase."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
